
all: pretrain finetune test


pretrain:
	OMP_NUM_THREADS=8 python -m torch.distributed.launch --nproc_per_node=2 --master_port 29502 main_pretrain.py \
		--batch_size 64 \
		--accum_iter 8 \
		--model mae_swin_large_256 \
		--mask_regular \
		--vis_mask_ratio 0.25 \
		--input_size 256 \
		--token_size 16 \
		--norm_pix_loss \
		--mask_ratio 0.75 \
		--epochs 800 \
		--warmup_epochs 40 \
		--blr 1.5e-4 \
		--weight_decay 0.05 \
		--data_path ../huaweidata/pretrain-labled4k_test4k \
		--log_dir ./work_dirs/unlabled4k_test4k/pretrain \
		--output_dir ./work_dirs/unlabled4k_test4k/pretrain

finetune:
	OMP_NUM_THREADS=8 python -m torch.distributed.launch --nproc_per_node=2 --master_port 29502 main_finetune.py \
		--input_size 256 \
		--batch_size 16 \
		--accum_iter 4 \
		--model swin_large_256 \
		--finetune ./work_dirs/unlabled4k_test4k/pretrain/checkpoint-99.pth \
		--epochs 100 \
		--blr 5e-4 --layer_decay 0.7 \
		--weight_decay 0.05 --drop_path 0.2 --reprob 0.25 --mixup 0.8 --cutmix 1.0 \
		--dist_eval --data_path ../huaweidata/lxm-2-resize-256 \
		--nb_classes 2 \
		--log_dir ./work_dirs/unlabled4k_test4k/finetune \
		--output_dir ./work_dirs/unlabled4k_test4k/finetune

test:
	OMP_NUM_THREADS=8 python -m torch.distributed.launch --nproc_per_node=1 --master_port 29501 prob.py \
		--input_size 256 \
		--batch_size 16 \
		--accum_iter 4 \
		--model swin_large_256 \
		--load_from ./work_dirs/unlabled4k_test4k/finetune/checkpoint-46.pth \
		--epochs 100 \
		--blr 5e-4 --layer_decay 0.7 \
		--weight_decay 0.05 --drop_path 0.2 --reprob 0.25 --mixup 0.8 --cutmix 1.0 \
		--dist_eval \
		--data_path ../huaweidata/test_images_256_noducp/class0 \
		--nb_classes 2 \
		--log_dir ./work_dirs/unlabled4k_test4k/test \
		--output_dir ./work_dirs/unlabled4k_test4k/test